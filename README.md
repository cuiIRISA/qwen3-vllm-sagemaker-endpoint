# qwen3-vllm-sagemaker-endpoint

Thanks to vLLM's official SageMaker Endpoint support, online serving with SageMaker Entrypoint is straightforward.

https://docs.vllm.ai/en/stable/examples/online_serving/sagemaker-entrypoint.html

This repository showcases a Dockerfile that can be tested both locally and on a SageMaker endpoint. See the guide for Qwen3 8B and 30B model local testing, and an example of deploying on a SageMaker endpoint in the vllm_deploy notebook.
