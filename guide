


docker run --gpus all \
  -p 8080:8080 \
  -e HF_HOME=/home/ec2-user/SageMaker/cache/huggingface \
  -v /home/ec2-user/SageMaker/cache/huggingface:/home/ec2-user/SageMaker/cache/huggingface \
  -e SM_VLLM_MODEL=Qwen/Qwen3-8B \
  -e SM_VLLM_TENSOR_PARALLEL_SIZE=1 \
  -e SM_VLLM_MAX_MODEL_LEN=16384 \
  -e SM_VLLM_MAX_NUM_SEQS=8 \
  -e SM_VLLM_GPU_MEMORY_UTILIZATION=0.9 \
  vllm_env:v0.9.0


Invocation 
curl http://localhost:8080/v1/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen3-8B",
    "prompt": "Hello, how are you?",
    "max_tokens": 50
  }'

Streaming 
curl -N http://localhost:8080/v1/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen3-8B",
    "prompt": "Once upon a time in a galaxy far, far away",
    "max_tokens": 100,
    "stream": true
  }'